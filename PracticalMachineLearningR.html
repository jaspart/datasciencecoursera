<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Practical Machine Learning Project - Coursera</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Practical Machine Learning Project - Coursera</h1>

<h2>Acknowlegements</h2>

<p>I would like to thank the Human Activity Recognition (see : <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>) for providing the data for this project. </p>

<h2>Choices justifications</h2>

<p>The random forest algorithm has been choosen for this analysis for the following reasons:</p>

<ul>
<li>  Detection of variable importance</li>
<li>  Embedded cross validation</li>
<li>  Need of predictions</li>
</ul>

<h2>Data analysis and cleaning</h2>

<p>First, we load the data:</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">training &lt;- read.csv(&quot;pml-training.csv&quot;)
testing &lt;- read.csv(&quot;pml-testing.csv&quot;)
</code></pre>

<p>Then, we remove the first columns containing data unrelated to the outcome of the experience.
Such as the name of the cobaye, date of the experience, and window :</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">training &lt;- training[,-c(1,2,3,4,5,6,7)]
testing &lt;- testing[,-c(1,2,3,4,5,6,7)]
</code></pre>

<p>After, we remove the columns that contain NA values.</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">training &lt;-training[,colSums(is.na(testing))==0]
testing &lt;-testing[,colSums(is.na(testing))==0]
</code></pre>

<h2>Building model</h2>

<p>To apply the random forest algorithm in order to get our model, we run:</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">library(randomForest)
modelFit &lt;- randomForest(classe ~., data = training)
</code></pre>

<h2>Model prediction</h2>

<p>We can now predict the testing values by using the model:</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE"> prediction &lt;- predict(modelFit, testing)
 prediction
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
 B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
Levels: A B C D E
</code></pre>

<h2>Cross validation</h2>

<h3>Embedded cross validation</h3>

<p>As you can read in <a href="https://www.stat.berkeley.edu/%7Ebreiman/RandomForests/cc_home.htm#ooberr">Breiman&#39;s official documentation</a></p>

<blockquote>
<p>&ldquo;In random forests, there is no need for cross-validation or a separate test set to get an unbiased estimate of the test set error. It is estimated internally&hellip;&rdquo;</p>
</blockquote>

<p>So, the model is carrying the information (confusion matrix and error rate) :</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">&gt; modelFit

Call:
 randomForest(formula = classe ~ ., data = training) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 7

        OOB estimate of  error rate: 0.3%
Confusion matrix:
     A    B    C    D    E  class.error
A 5579    1    0    0    0 0.0001792115
B   12 3783    2    0    0 0.0036871214
C    0   12 3410    0    0 0.0035067212
D    0    0   23 3191    2 0.0077736318
E    0    0    1    5 3601 0.0016634322
</code></pre>

<p>The error rate is in the order of 0.3%.</p>

<h3>Calculated cross validation</h3>

<p>We can try to calculate it &ldquo;manually&rdquo;.
Notice : the testing dataset has no class value to help us verify the accuracy.</p>

<p>In order to check the accuracy we can divide the training dataset into 2 dataset:</p>

<ul>
<li>CVtraining : the training dataset for the crossvalidation operation</li>
<li>CVtesting : the testing dataset that will help calculate the accuracy</li>
</ul>

<p>Use CVtraining to get a model and use CVtesting to validate our model:</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">library(caret)
inTrain &lt;- createDataPartition(y=training$classe, p=0.75, list=FALSE)
CVtraining&lt;- training[inTrain,]
CVtesting&lt;- training[-inTrain,]
modelFit &lt;- randomForest(classe ~., data = CVtraining)
prediction &lt;- predict(modelFit, CVtesting)
</code></pre>

<p>The confusion matrix can be obtained as follow:</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">confusionMatrix &lt;- table(prediction, CVtesting$classe)
confusionMatrix

       A    B    C    D    E
  A 1394    5    0    0    0
  B    1  942    5    0    0
  C    0    2  850    4    0
  D    0    0    0  799    2
  E    0    0    0    1  899

</code></pre>

<p>The accuracy value can be obtained as follow:</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">accuracy &lt;- sum(diag(confusionMatrix))/sum(confusionMatrix)
accuracy
[1] 0.004078303
</code></pre>

<p>The calculated error rate is in the order of 0.4% (~0.408 %) :</p>

<pre><code class="r results=&#39;asis&#39;, echo=FALSE">(1-accuracy)*100
[1] 0.4078303
</code></pre>

</body>

</html>
